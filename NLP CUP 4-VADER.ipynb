{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NLP Cup Event #4\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nprint('The scikit-learn version is {}.'.format(sklearn.__version__))","execution_count":18,"outputs":[{"output_type":"stream","text":"The scikit-learn version is 0.23.1.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.getcwd()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/mmai-nlp-cup-event-4-section-2/sentiment_train.csv\") \ndf.info()\ndf.head()\n\n# Note that since we aren't building a ML model, we don't need to split the data into training and validation","execution_count":20,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8782 entries, 0 to 8781\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   id         8782 non-null   object\n 1   text       8782 non-null   object\n 2   sentiment  8782 non-null   int64 \ndtypes: int64(1), object(2)\nmemory usage: 206.0+ KB\n","name":"stdout"},{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"           id                                               text  sentiment\n0  35987ef851           Got a deadline to meet!!! No TGIF for me          0\n1  a429255434                        G`day  Thanx for following.          1\n2  c848cca377   that`s cool! i think del`s going to korea sam...          1\n3  d4d8e06110         Ugh! I can`t access through my mobile web!          0\n4  2916e56486                That sounds like a good compromise.          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35987ef851</td>\n      <td>Got a deadline to meet!!! No TGIF for me</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a429255434</td>\n      <td>G`day  Thanx for following.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c848cca377</td>\n      <td>that`s cool! i think del`s going to korea sam...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d4d8e06110</td>\n      <td>Ugh! I can`t access through my mobile web!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2916e56486</td>\n      <td>That sounds like a good compromise.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install vaderSentiment\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nSID=SentimentIntensityAnalyzer()\nSID.polarity_scores(df)\n","execution_count":21,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: vaderSentiment in /opt/conda/lib/python3.7/site-packages (3.3.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from vaderSentiment) (2.23.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->vaderSentiment) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->vaderSentiment) (2020.4.5.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->vaderSentiment) (1.24.3)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->vaderSentiment) (2.9)\n","name":"stdout"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the balance of the data\ndf.sentiment.value_counts()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"1    4391\n0    4391\nName: sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Oh man, this list is not very complete. \nneg_words = ['bad', 'worst', 'unhappy', 'Ugh', 'ouch', 'abysmal', 'angry','awful','atrocious','appalling','bad','belligerent','confused','crazy','deprived','dismal','distress','dishonest','detrimental','disgusting','depressed','damaging','enraged','fail','faulty','foul','gross','harmful','hostile','hurt','hideous','horrible','hurtful','insane','insidious','malicious','mean','monstrous','naive','nasty','negative','never','noxious','objectionable','offensive','pain','poor','pessimistic','questionable','rotten','rude','sad','scary','shocking','stupid','substandard','stressful','sick','sorry','terrible','terrifying','ugly','unfavorable','unjust','unsatisfactory','unwanted','unhappy','unfair','unpleasant','upset','vicious','woeful','wicked','yucky','zero']\npos_words = ['good', 'great', 'thanks', 'happy','absolutely','adorable','amazing','approve','awesome','agree','admire','agreeable','appealing','attractive','beneficial','brilliant','beautiful','bliss','calm','charming','creative','dazzling','delight','distinguished','effective','easy','encouraging','energized','excellent','ecstatic','efficient','elegant','exciting','fabulous','fair','fantastic','fine','fortunate','favorable','fun','generous','good','great','genius','genuine','honored','happy','honest','honorable','intelligent','innovative','impressive','jovial','joy','jubilant','lively','lovely','marvelous','meaningful','meritorious','nice','novel','optimistic','pleasant','positive','pretty','proud','perfect','pleasurable','powerful','phenomenal','plentiful','popular','refreshing','remarkable','resounding','rewarding','sunny','satisfactory','super','successful','superb','terrific','thriving','truthful','thrilling','trusting','valued','vibrant','vigorous','victorious','wonderful','wow','welcome','wondrous','well','worthy','yes','zeal']\n\n\ndef my_sentiment_analyzer(documents):\n    \"\"\"This function takes a list of documents and returns a list of corresponding sentiment predictions.\"\"\"\n\n    preds = np.zeros(len(documents))\n\n    for i, doc in enumerate(documents):\n        score = 0\n        score=SID.polarity_scores(doc)\n        if score[\"compound\"] >= 0:\n            preds[i]=1\n        else:\n            preds[i]=0\n    return preds\n        \n        #for word in doc.split():\n           # if word in pos_words:\n               # score = score + 1\n           # elif word in neg_words:\n                #score = score - 1\n        \n       # if score >= 0:\n           # preds[i] = 1\n        #else:\n            #preds[i] = 0\n\n    #return preds","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Estimate Model Performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\npreds = my_sentiment_analyzer(df['text'])\n\nprint(confusion_matrix(df['sentiment'], preds))\nprint()\nprint(classification_report(df['sentiment'], preds))","execution_count":29,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Score' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-72cf9936ff7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_sentiment_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-33abbe82b579>\u001b[0m in \u001b[0;36mmy_sentiment_analyzer\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mScore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compound\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Score' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[preds != df['sentiment']]","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"              id                                               text  sentiment\n0     35987ef851           Got a deadline to meet!!! No TGIF for me          0\n3     d4d8e06110         Ugh! I can`t access through my mobile web!          0\n7     bdb3d43938  Its not looking too good outside  if this cont...          0\n13    fd285fe74a               me too. I hate my computer so much..          0\n16    4ace4014c4  WH Correspondant`s Dinner Rocked! Wanda Sykes ...          1\n...          ...                                                ...        ...\n8774  7575d5433c  : What, you`re not really an alcoholic? I AM V...          0\n8775  69d743f966   There`s very few film/TV jobs, especially in ...          0\n8779  55f011fcb2  Missing brandon. Wanting to talk to anthony. S...          0\n8780  9e5e8ab6a4                                  I miss matt today          0\n8781  d70ed4038d                      Gahh ! This weather sucksss !          0\n\n[3735 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35987ef851</td>\n      <td>Got a deadline to meet!!! No TGIF for me</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d4d8e06110</td>\n      <td>Ugh! I can`t access through my mobile web!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>bdb3d43938</td>\n      <td>Its not looking too good outside  if this cont...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>fd285fe74a</td>\n      <td>me too. I hate my computer so much..</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>4ace4014c4</td>\n      <td>WH Correspondant`s Dinner Rocked! Wanda Sykes ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8774</th>\n      <td>7575d5433c</td>\n      <td>: What, you`re not really an alcoholic? I AM V...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8775</th>\n      <td>69d743f966</td>\n      <td>There`s very few film/TV jobs, especially in ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8779</th>\n      <td>55f011fcb2</td>\n      <td>Missing brandon. Wanting to talk to anthony. S...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8780</th>\n      <td>9e5e8ab6a4</td>\n      <td>I miss matt today</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8781</th>\n      <td>d70ed4038d</td>\n      <td>Gahh ! This weather sucksss !</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3735 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Create Submission File on Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/mmai-nlp-cup-event-4-section-2/sentiment_test.csv')\n\n# Use your model to make predictions\npred_test = my_sentiment_analyzer(test_df['text'])\n\n# We will look at the predicted prices to ensure we have something sensible.\nprint(pred_test)\n\nmy_submission = pd.DataFrame({'id': test_df.id, 'predicted': pred_test.astype(int)})\n\nmy_submission.head()\n\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":26,"outputs":[{"output_type":"stream","text":"[0. 1. 0. ... 1. 1. 1.]\n","name":"stdout"},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"           id  predicted\n0  998af5bf96          0\n1  4ac01c9f90          1\n2  e2e3bbf3aa          0\n3  2614f7b5de          1\n4  378bf58fa3          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>998af5bf96</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4ac01c9f90</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e2e3bbf3aa</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2614f7b5de</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>378bf58fa3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"small_sklearn_kernel","language":"python","name":"small_sklearn_kernel"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":4}